{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opensoundscape as ops\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "from shapely.geometry import Point\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "from opensoundscape.localization import SynchronizedRecorderArray\n",
    "from opensoundscape.localization.position_estimate import PositionEstimate\n",
    "from opensoundscape.localization.position_estimate import positions_to_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.getenv(\"BASE_DIR\")\n",
    "if not BASE_DIR:\n",
    "    raise ValueError(\"BASE_DIR environment variable is not set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate speed of sound\n",
    "\n",
    "1. We calculate distance between two furthest recording points.\n",
    "2. Then use speed of sound in this conditions to calculate travel time\n",
    "\n",
    "For speed of sound, followed this webpage: http://resource.npl.co.uk/acoustics/techguides/soundseawater/. Used water temp = 28.5C, Salinity = 33.58 (taken from Rosalina et al., 2024 for the month of July in Spermonde in 2022*), Depth = 17m, Latitude = -4Â° 55' 47.712\". Using the Mackenzie equation this gives 1541.007 m/s.\n",
    "\n",
    "The study sites can be found here: https://www.google.com/maps/d/edit?mid=1etfYnjSsrtYnjrdnpzZR62knsrIj1t4&usp=sharing \n",
    "\n",
    "\n",
    "*SALINITY DISTRIBUTION PATTERN IN SPERMONDE WATERS USING REMOTE SENSING DATA (COPERNICUS MARINE SERVICE) IN 2022. (Google 'Spermonde salinity' to find this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance: 40.743 km\n",
      "Travel time at 1541.007 m/s: 26.439 s\n",
      "Distance halved: 20.372 km\n"
     ]
    }
   ],
   "source": [
    "# Calc distance and travel time at 1541.007 m/s\n",
    "# !pip install geopy\n",
    "\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# Recording-site coords\n",
    "coord_a = (-4.70878, 119.32657)   # M35 Samatellu\n",
    "coord_b = (-5.07711, 119.31749)   # M43 Barrang Caddi\n",
    "\n",
    "speed_m_s = 1541.007  # speed in metres per second\n",
    "\n",
    "# Distance\n",
    "distance_km = geodesic(coord_a, coord_b).kilometers\n",
    "distance_halved = distance_km / 2\n",
    "distance_m = distance_km * 1000\n",
    "\n",
    "\n",
    "# Travel time\n",
    "travel_time_s = distance_m / speed_m_s\n",
    "travel_time_halved_s = distance_halved * 1000 / speed_m_s\n",
    "\n",
    "print(f\"Distance: {distance_km:.3f} km\")\n",
    "print(f\"Travel time at {speed_m_s} m/s: {travel_time_s:.3f} s\")\n",
    "print(f\"Distance halved: {distance_halved:.3f} km\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate len of windows to check for co-occuring blasts\n",
    "This code reports possible detections of the same blast event if we use a reasonable time window for which we should check if blasts co-occur at the same time in different recorders.\n",
    "\n",
    "To calc the reasonable window:\n",
    "1. We used Hydromoths, for which Open Acoustics expect **clock drift** to be around 0.25sec per day: https://www.openacousticdevices.info/support/device-support/question-about-timing/dl-focus. We recorded on four unique days, so worst case scenario if one recorder drifted one way and another the opposite, that gives a 2sec misalignment. So, if a bomb was heard at the northern or southern most recorder, it would take 26.439 +- 2 second to reach the opposite recorder which is 28.439 sec maximum.\n",
    "3. However, the **bomb model does not work on exact start timestamps for bombs**, it uses windows 2.88sec in length. So in theory, a timestamp given for a bomb may be 2.88sec earlier than the actual bomb (of course it would likely be less, but we take this maximum to be conservative). So we add this to get **31.319sec**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Events in 3 files:\n",
      "- A_M35.csv: File=20240701_141200.WAV, Timestamp=00:00:14\n",
      "- C_M41.csv: File=20240701_141200.WAV, Timestamp=00:00:14\n",
      "- D_M43.csv: File=20240701_141200.WAV, Timestamp=00:00:25\n",
      "---\n",
      "- B_M36.csv: File=20240701_232301.wav, Timestamp=00:00:27\n",
      "- C_M41.csv: File=20240701_232300.WAV, Timestamp=00:00:30\n",
      "- A_M35.csv: File=20240701_232300.WAV, Timestamp=00:00:36\n",
      "---\n",
      "- B_M36.csv: File=20240702_002802.wav, Timestamp=00:00:31\n",
      "- C_M41.csv: File=20240702_002800.WAV, Timestamp=00:00:34\n",
      "- A_M35.csv: File=20240702_002800.WAV, Timestamp=00:00:38\n",
      "---\n",
      "- B_M36.csv: File=20240702_094501.wav, Timestamp=00:00:02\n",
      "- C_M41.csv: File=20240702_094500.WAV, Timestamp=00:00:10\n",
      "- D_M43.csv: File=20240702_094500.WAV, Timestamp=00:00:21\n",
      "---\n",
      "- B_M36.csv: File=20240702_111402.wav, Timestamp=00:00:00\n",
      "- A_M35.csv: File=20240702_111401.WAV, Timestamp=00:00:04\n",
      "- C_M41.csv: File=20240702_111400.WAV, Timestamp=00:00:08\n",
      "---\n",
      "- C_M41.csv: File=20240702_125900.WAV, Timestamp=00:00:00\n",
      "- B_M36.csv: File=20240702_125901.wav, Timestamp=00:00:00\n",
      "- A_M35.csv: File=20240702_125901.WAV, Timestamp=00:00:04\n",
      "---\n",
      "- B_M36.csv: File=20240702_134101.wav, Timestamp=00:00:31\n",
      "- A_M35.csv: File=20240702_134101.WAV, Timestamp=00:00:34\n",
      "- C_M41.csv: File=20240702_134100.WAV, Timestamp=00:00:36\n",
      "---\n",
      "- C_M41.csv: File=20240702_141000.WAV, Timestamp=00:00:21\n",
      "- D_M43.csv: File=20240702_141000.WAV, Timestamp=00:00:27\n",
      "- B_M36.csv: File=20240702_141002.wav, Timestamp=00:00:27\n",
      "---\n",
      "- B_M36.csv: File=20240703_145901.wav, Timestamp=00:00:25\n",
      "- C_M41.csv: File=20240703_145901.WAV, Timestamp=00:00:28\n",
      "- A_M35.csv: File=20240703_145902.WAV, Timestamp=00:00:28\n",
      "---\n",
      "- B_M36.csv: File=20240703_151602.wav, Timestamp=00:00:21\n",
      "- C_M41.csv: File=20240703_151601.WAV, Timestamp=00:00:25\n",
      "- A_M35.csv: File=20240703_151602.WAV, Timestamp=00:00:25\n",
      "---\n",
      "- B_M36.csv: File=20240703_173802.wav, Timestamp=00:00:17\n",
      "- C_M41.csv: File=20240703_173801.WAV, Timestamp=00:00:21\n",
      "- A_M35.csv: File=20240703_173802.WAV, Timestamp=00:00:21\n",
      "---\n",
      "- B_M36.csv: File=20240704_044901.wav, Timestamp=00:00:25\n",
      "- C_M41.csv: File=20240704_044901.WAV, Timestamp=00:00:28\n",
      "- A_M35.csv: File=20240704_044902.WAV, Timestamp=00:00:28\n",
      "---\n",
      "- C_M41.csv: File=20240704_084201.WAV, Timestamp=00:00:25\n",
      "- D_M43.csv: File=20240704_084201.WAV, Timestamp=00:00:43\n",
      "- B_M36.csv: File=20240704_084202.wav, Timestamp=00:00:51\n",
      "---\n",
      "- D_M43.csv: File=20240704_084201.WAV, Timestamp=00:00:43\n",
      "- C_M41.csv: File=20240704_084201.WAV, Timestamp=00:00:48\n",
      "- B_M36.csv: File=20240704_084202.wav, Timestamp=00:00:51\n",
      "---\n",
      "\n",
      "Events in 2 files:\n",
      "- A_M35.csv: File=20240628_102300.WAV, Timestamp=00:00:41\n",
      "- B_M36.csv: File=20240628_102300.wav, Timestamp=00:00:41\n",
      "---\n",
      "- C_M41.csv: File=20240701_114700.WAV, Timestamp=00:00:47\n",
      "- D_M43.csv: File=20240701_114700.WAV, Timestamp=00:00:48\n",
      "---\n",
      "- A_M35.csv: File=20240701_141200.WAV, Timestamp=00:00:14\n",
      "- C_M41.csv: File=20240701_141200.WAV, Timestamp=00:00:14\n",
      "---\n",
      "- A_M35.csv: File=20240701_143200.WAV, Timestamp=00:00:46\n",
      "- C_M41.csv: File=20240701_143200.WAV, Timestamp=00:00:50\n",
      "---\n",
      "- B_M36.csv: File=20240701_232301.wav, Timestamp=00:00:27\n",
      "- C_M41.csv: File=20240701_232300.WAV, Timestamp=00:00:30\n",
      "---\n",
      "- B_M36.csv: File=20240702_002802.wav, Timestamp=00:00:31\n",
      "- C_M41.csv: File=20240702_002800.WAV, Timestamp=00:00:34\n",
      "---\n",
      "- D_M43.csv: File=20240702_064100.WAV, Timestamp=00:00:51\n",
      "- C_M41.csv: File=20240702_064200.WAV, Timestamp=00:00:00\n",
      "---\n",
      "- C_M41.csv: File=20240702_064200.WAV, Timestamp=00:00:15\n",
      "- D_M43.csv: File=20240702_064200.WAV, Timestamp=00:00:41\n",
      "---\n",
      "- D_M43.csv: File=20240702_064200.WAV, Timestamp=00:00:41\n",
      "- C_M41.csv: File=20240702_064200.WAV, Timestamp=00:00:48\n",
      "---\n",
      "- D_M43.csv: File=20240702_065400.WAV, Timestamp=00:00:51\n",
      "- C_M41.csv: File=20240702_065500.WAV, Timestamp=00:00:00\n",
      "---\n",
      "- C_M41.csv: File=20240702_065500.WAV, Timestamp=00:00:00\n",
      "- D_M43.csv: File=20240702_065500.WAV, Timestamp=00:00:17\n",
      "---\n",
      "- D_M43.csv: File=20240702_085700.WAV, Timestamp=00:00:17\n",
      "- C_M41.csv: File=20240702_085700.WAV, Timestamp=00:00:21\n",
      "---\n",
      "- D_M43.csv: File=20240702_091300.WAV, Timestamp=00:00:38\n",
      "- C_M41.csv: File=20240702_091300.WAV, Timestamp=00:00:43\n",
      "---\n",
      "- C_M41.csv: File=20240702_091300.WAV, Timestamp=00:00:43\n",
      "- D_M43.csv: File=20240702_091400.WAV, Timestamp=00:00:08\n",
      "---\n",
      "- B_M36.csv: File=20240702_094501.wav, Timestamp=00:00:02\n",
      "- C_M41.csv: File=20240702_094500.WAV, Timestamp=00:00:10\n",
      "---\n",
      "- C_M41.csv: File=20240702_100200.WAV, Timestamp=00:00:25\n",
      "- D_M43.csv: File=20240702_100200.WAV, Timestamp=00:00:25\n",
      "---\n",
      "- D_M43.csv: File=20240702_104900.WAV, Timestamp=00:00:04\n",
      "- C_M41.csv: File=20240702_104900.WAV, Timestamp=00:00:07\n",
      "---\n",
      "- D_M43.csv: File=20240702_110000.WAV, Timestamp=00:00:36\n",
      "- C_M41.csv: File=20240702_110000.WAV, Timestamp=00:00:38\n",
      "---\n",
      "- B_M36.csv: File=20240702_111402.wav, Timestamp=00:00:00\n",
      "- A_M35.csv: File=20240702_111401.WAV, Timestamp=00:00:04\n",
      "---\n",
      "- C_M41.csv: File=20240702_111500.WAV, Timestamp=00:00:04\n",
      "- D_M43.csv: File=20240702_111500.WAV, Timestamp=00:00:10\n",
      "---\n",
      "- B_M36.csv: File=20240702_111501.wav, Timestamp=00:00:51\n",
      "- C_M41.csv: File=20240702_111600.WAV, Timestamp=00:00:01\n",
      "---\n",
      "- C_M41.csv: File=20240702_120600.WAV, Timestamp=00:00:12\n",
      "- D_M43.csv: File=20240702_120600.WAV, Timestamp=00:00:20\n",
      "---\n",
      "- C_M41.csv: File=20240702_125900.WAV, Timestamp=00:00:00\n",
      "- B_M36.csv: File=20240702_125901.wav, Timestamp=00:00:00\n",
      "---\n",
      "- D_M43.csv: File=20240702_132900.WAV, Timestamp=00:00:24\n",
      "- C_M41.csv: File=20240702_132900.WAV, Timestamp=00:00:30\n",
      "---\n",
      "- A_M35.csv: File=20240702_133301.WAV, Timestamp=00:00:40\n",
      "- B_M36.csv: File=20240702_133301.wav, Timestamp=00:00:41\n",
      "---\n",
      "- C_M41.csv: File=20240702_133900.WAV, Timestamp=00:00:44\n",
      "- D_M43.csv: File=20240702_133900.WAV, Timestamp=00:00:50\n",
      "---\n",
      "- B_M36.csv: File=20240702_134101.wav, Timestamp=00:00:31\n",
      "- A_M35.csv: File=20240702_134101.WAV, Timestamp=00:00:34\n",
      "---\n",
      "- C_M41.csv: File=20240702_141000.WAV, Timestamp=00:00:21\n",
      "- D_M43.csv: File=20240702_141000.WAV, Timestamp=00:00:27\n",
      "---\n",
      "- A_M35.csv: File=20240702_152801.WAV, Timestamp=00:00:05\n",
      "- B_M36.csv: File=20240702_152802.wav, Timestamp=00:00:12\n",
      "---\n",
      "- C_M41.csv: File=20240702_155000.WAV, Timestamp=00:00:24\n",
      "- B_M36.csv: File=20240702_155002.wav, Timestamp=00:00:23\n",
      "---\n",
      "- D_M43.csv: File=20240702_161200.WAV, Timestamp=00:00:48\n",
      "- C_M41.csv: File=20240702_161200.WAV, Timestamp=00:00:51\n",
      "---\n",
      "- C_M41.csv: File=20240702_165700.WAV, Timestamp=00:00:20\n",
      "- D_M43.csv: File=20240702_165700.WAV, Timestamp=00:00:21\n",
      "---\n",
      "- A_M35.csv: File=20240702_180300.WAV, Timestamp=00:00:02\n",
      "- B_M36.csv: File=20240702_180301.wav, Timestamp=00:00:08\n",
      "---\n",
      "- B_M36.csv: File=20240702_222701.wav, Timestamp=00:00:00\n",
      "- A_M35.csv: File=20240702_222701.WAV, Timestamp=00:00:07\n",
      "---\n",
      "- D_M43.csv: File=20240703_082600.WAV, Timestamp=00:00:07\n",
      "- C_M41.csv: File=20240703_082600.WAV, Timestamp=00:00:08\n",
      "---\n",
      "- D_M43.csv: File=20240703_085000.WAV, Timestamp=00:00:43\n",
      "- C_M41.csv: File=20240703_085000.WAV, Timestamp=00:00:50\n",
      "---\n",
      "- D_M43.csv: File=20240703_092500.WAV, Timestamp=00:00:17\n",
      "- C_M41.csv: File=20240703_092500.WAV, Timestamp=00:00:18\n",
      "---\n",
      "- D_M43.csv: File=20240703_092600.WAV, Timestamp=00:00:31\n",
      "- C_M41.csv: File=20240703_092600.WAV, Timestamp=00:00:33\n",
      "---\n",
      "- D_M43.csv: File=20240703_093200.WAV, Timestamp=00:00:12\n",
      "- C_M41.csv: File=20240703_093200.WAV, Timestamp=00:00:14\n",
      "---\n",
      "- C_M41.csv: File=20240703_093300.WAV, Timestamp=00:00:04\n",
      "- D_M43.csv: File=20240703_093300.WAV, Timestamp=00:00:04\n",
      "---\n",
      "- C_M41.csv: File=20240703_111000.WAV, Timestamp=00:00:43\n",
      "- D_M43.csv: File=20240703_111000.WAV, Timestamp=00:00:51\n",
      "---\n",
      "- C_M41.csv: File=20240703_111200.WAV, Timestamp=00:00:02\n",
      "- D_M43.csv: File=20240703_111200.WAV, Timestamp=00:00:11\n",
      "---\n",
      "- D_M43.csv: File=20240703_115900.WAV, Timestamp=00:00:01\n",
      "- C_M41.csv: File=20240703_115900.WAV, Timestamp=00:00:04\n",
      "---\n",
      "- D_M43.csv: File=20240703_131600.WAV, Timestamp=00:00:12\n",
      "- C_M41.csv: File=20240703_131600.WAV, Timestamp=00:00:37\n",
      "---\n",
      "- D_M43.csv: File=20240703_131700.WAV, Timestamp=00:00:12\n",
      "- C_M41.csv: File=20240703_131700.WAV, Timestamp=00:00:21\n",
      "---\n",
      "- B_M36.csv: File=20240703_145901.wav, Timestamp=00:00:25\n",
      "- C_M41.csv: File=20240703_145901.WAV, Timestamp=00:00:28\n",
      "---\n",
      "- B_M36.csv: File=20240703_151602.wav, Timestamp=00:00:21\n",
      "- C_M41.csv: File=20240703_151601.WAV, Timestamp=00:00:25\n",
      "---\n",
      "- B_M36.csv: File=20240703_173802.wav, Timestamp=00:00:17\n",
      "- C_M41.csv: File=20240703_173801.WAV, Timestamp=00:00:21\n",
      "---\n",
      "- B_M36.csv: File=20240704_044901.wav, Timestamp=00:00:25\n",
      "- C_M41.csv: File=20240704_044901.WAV, Timestamp=00:00:28\n",
      "---\n",
      "- D_M43.csv: File=20240704_071601.WAV, Timestamp=00:00:24\n",
      "- C_M41.csv: File=20240704_071601.WAV, Timestamp=00:00:31\n",
      "---\n",
      "- D_M43.csv: File=20240704_082501.WAV, Timestamp=00:00:20\n",
      "- C_M41.csv: File=20240704_082501.WAV, Timestamp=00:00:21\n",
      "---\n",
      "- D_M43.csv: File=20240704_084201.WAV, Timestamp=00:00:20\n",
      "- C_M41.csv: File=20240704_084201.WAV, Timestamp=00:00:25\n",
      "---\n",
      "- D_M43.csv: File=20240704_084501.WAV, Timestamp=00:00:04\n",
      "- C_M41.csv: File=20240704_084501.WAV, Timestamp=00:00:10\n",
      "---\n",
      "- D_M43.csv: File=20240704_091701.WAV, Timestamp=00:00:38\n",
      "- C_M41.csv: File=20240704_091701.WAV, Timestamp=00:00:40\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# This cell loads bomb detection CSVs, computes full event timestamps,\n",
    "# clusters events that fall within a defined time window,\n",
    "# and prints out groups detected simultaneously across multiple recorders.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "INPUT_PATH = Path(os.path.join(BASE_DIR, \"bomb_fishing/data\"))\n",
    "\n",
    "# Maximum allowable difference between events to consider co-occurring\n",
    "TIME_WINDOW_S: float = 31.319\n",
    "window_delta: timedelta = timedelta(seconds=TIME_WINDOW_S)\n",
    "\n",
    "@dataclass\n",
    "class BombEvent:\n",
    "    \"\"\"\n",
    "    Represents a single bomb detection event.\n",
    "\n",
    "    Attributes:\n",
    "        csv: Name of the CSV file where event was recorded\n",
    "        file: WAV filename containing the timestamp reference\n",
    "        timestamp: String HH:MM:SS offset into the WAV file\n",
    "        when: Absolute datetime of the event\n",
    "    \"\"\"\n",
    "    csv: str\n",
    "    file: str\n",
    "    timestamp: str\n",
    "    when: datetime\n",
    "\n",
    "\n",
    "def load_events(input_dir: Path) -> List[BombEvent]:\n",
    "    \"\"\"\n",
    "    Load bomb events marked 'y' from CSVs, compute absolute timestamps.\n",
    "\n",
    "    Returns list of BombEvent.\n",
    "    \"\"\"\n",
    "    events: List[BombEvent] = []\n",
    "    for csv_file in sorted(input_dir.glob(\"*.csv\")):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        df = df[df[\"Bomb\"] == \"y\"].copy()\n",
    "        if df.empty:\n",
    "            continue\n",
    "        # parse base datetime from filename prefix\n",
    "        df[\"base_dt\"] = (\n",
    "            df[\"File\"]\n",
    "            .str.extract(r\"(\\d{8}_\\d{6})\")[0]\n",
    "            .apply(lambda s: datetime.strptime(s, \"%Y%m%d_%H%M%S\"))\n",
    "        )\n",
    "        # get offset and compute absolute time\n",
    "        df[\"offset\"] = pd.to_timedelta(df[\"Timestamp (HH:MM:SS)\"])\n",
    "        df[\"when\"] = df[\"base_dt\"] + df[\"offset\"]\n",
    "        for row in df.itertuples():\n",
    "            events.append(\n",
    "                BombEvent(\n",
    "                    csv=csv_file.name,\n",
    "                    file=row.File,\n",
    "                    timestamp=row._2,\n",
    "                    when=row.when,\n",
    "                )\n",
    "            )\n",
    "    return events\n",
    "\n",
    "\n",
    "def cluster_events(events: List[BombEvent]) -> List[List[BombEvent]]:\n",
    "    \"\"\"\n",
    "    Slide a window across sorted events, grouping events within window_delta.\n",
    "    Picks the earliest event per CSV in each window and deduplicates clusters.\n",
    "    \"\"\"\n",
    "    sorted_events = sorted(events, key=lambda e: e.when)\n",
    "    clusters: List[List[BombEvent]] = []\n",
    "    seen = set()\n",
    "    start = 0\n",
    "    for end, evt in enumerate(sorted_events):\n",
    "        # advance start so window fits within time delta\n",
    "        while sorted_events[end].when - sorted_events[start].when > window_delta:\n",
    "            start += 1\n",
    "        window = sorted_events[start:end+1]\n",
    "        # select earliest event per CSV\n",
    "        per_csv = {}\n",
    "        for e in window:\n",
    "            per_csv.setdefault(e.csv, e)\n",
    "        if len(per_csv) >= 2:\n",
    "            # build cluster sorted by time\n",
    "            cluster = sorted(per_csv.values(), key=lambda x: x.when)\n",
    "            # dedupe based on csv names and times\n",
    "            key = tuple((e.csv, e.when.isoformat()) for e in cluster)\n",
    "            if key not in seen:\n",
    "                seen.add(key)\n",
    "                clusters.append(cluster)\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def print_clusters(clusters: List[List[BombEvent]]) -> None:\n",
    "    \"\"\"\n",
    "    Print clusters by descending number of distinct CSV sources.\n",
    "    \"\"\"\n",
    "    buckets = {4: [], 3: [], 2: []}\n",
    "    for grp in clusters:\n",
    "        count = len(grp)\n",
    "        if count in buckets:\n",
    "            buckets[count].append(grp)\n",
    "    for count in (4, 3, 2):\n",
    "        if not buckets[count]:\n",
    "            continue\n",
    "        print(f\"\\nEvents in {count} files:\")\n",
    "        for grp in buckets[count]:\n",
    "            for e in grp:\n",
    "                print(f\"- {e.csv}: File={e.file}, Timestamp={e.timestamp}\")\n",
    "            print(\"---\")\n",
    "\n",
    "# Load and cluster events\n",
    "events = load_events(INPUT_PATH)\n",
    "if not events:\n",
    "    print(\"No bomb events found in the directory.\")\n",
    "else:\n",
    "    clusters = cluster_events(events)\n",
    "    if clusters:\n",
    "        print_clusters(clusters)\n",
    "    else:\n",
    "        print(f\"No co-occurring events within {TIME_WINDOW_S} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats test to check random chance these events coincided\n",
    "After checking the spectrograms, eight blast events were found which appear to have been detected by 3 different recorders within the same window. However, we need to check the probability this could happen by chance.\n",
    "\n",
    "C M43, Bontosua, had the shortest recording time at 20240701_101100 to 20240704_104400. So we can use this as the most conservative (i.e)..\n",
    "\n",
    "We run a permutation 'Monte-carlo' test to find the chances these 9 events would co-occur given the total time by:\n",
    "- Randomly reassign each detection timestamp to a new location\n",
    "    within the full recording window [0, T] (in seconds).\n",
    "- Repeat this process `n_sims` times.\n",
    "- For each shuffle, count how many events in array A have a\n",
    "    corresponding event in both B and C within Â± window seconds. \n",
    "    Which is still 31.319 and hence very conservative as it allows bombs to occur up to 62.6sec apart.\n",
    "- Finally, return the proportion of shuffles that produced 9 or more\n",
    "    triple-overlapping events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected triple-overlaps under null: 0.00297\n",
      "95% CI: 0.00000â0.00000\n",
      "Observed 1 overlaps, p-value = 0.00297\n"
     ]
    }
   ],
   "source": [
    "# Stats test with expected overlaps and 95% CI\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Define recording window bounds explicitly\n",
    "start_dt = datetime.strptime(\"20240701_101100\", \"%Y%m%d_%H%M%S\")\n",
    "end_dt   = datetime.strptime(\"20240704_104400\", \"%Y%m%d_%H%M%S\")\n",
    "T        = (end_dt - start_dt).total_seconds()\n",
    "\n",
    "# Identify the three overlapping recorders (CSV names)\n",
    "overlap_csvs = sorted({e.csv for grp in clusters for e in grp})[:3]\n",
    "\n",
    "# Extract detection times (seconds from start) for each recorder\n",
    "arrays = {\n",
    "    name: np.array([(evt.when - start_dt).total_seconds()\n",
    "                    for evt in events if evt.csv == name])\n",
    "    for name in overlap_csvs\n",
    "}\n",
    "if len(arrays) < 3:\n",
    "    raise RuntimeError(\"Need three overlapping recorders for Monte Carlo test.\")\n",
    "\n",
    "tA, tB, tC = (arrays[overlap_csvs[i]] for i in range(3))\n",
    "\n",
    "# Monte Carlo permutations\n",
    "n_sims = 100_000\n",
    "counts = np.zeros(n_sims, dtype=int)\n",
    "\n",
    "for i in range(n_sims):\n",
    "    sA = np.random.rand(len(tA)) * T\n",
    "    sB = np.random.rand(len(tB)) * T\n",
    "    sC = np.random.rand(len(tC)) * T\n",
    "\n",
    "    # count how many of Aâs events co-occur in B and C within Â±window\n",
    "    cnt = sum(\n",
    "        1 for x in sA\n",
    "        if (np.any(np.abs(sB - x) <= TIME_WINDOW_S)\n",
    "            and np.any(np.abs(sC - x) <= TIME_WINDOW_S))\n",
    "    )\n",
    "    counts[i] = cnt\n",
    "\n",
    "# Observed count (We observed 8, but put 1 and then we can say chances \n",
    "# of 1 or more co-occuring to be conservative)\n",
    "obs_count = 1\n",
    "\n",
    "# p-value: fraction of sims with â¥ obs_count overlaps\n",
    "p_val = np.mean(counts >= obs_count)\n",
    "\n",
    "# Expected number of overlaps and 95% CI under null\n",
    "mean_cnt   = counts.mean()\n",
    "ci_lower, ci_upper = np.percentile(counts, [2.5, 97.5])\n",
    "\n",
    "# Print results\n",
    "print(f\"Expected triple-overlaps under null: {mean_cnt:.5f}\")\n",
    "print(f\"95% CI: {ci_lower:.5f}â{ci_upper:.5f}\")\n",
    "print(f\"Observed {obs_count} overlaps, p-value = {p_val:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open soundscape localisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert recorder coordinates to OpenSoundscapes UTM format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recorder positions (latitude, longitude)\n",
    "a_coords_geo: List[Tuple[float, float]] = [\n",
    "    (-4.70878, 119.32657),  # A\n",
    "    (-4.80363, 119.32858),  # B\n",
    "    (-4.92992, 119.31595),  # C\n",
    "    #(-5.07711, 119.31749),  # D we don't use D\n",
    "]\n",
    "\n",
    "# Access the list of recorder positions\n",
    "df_coords = pd.DataFrame(a_coords_geo, columns=[\"lat\",\"lon\"], index=[\"A\",\"B\",\"C\"])\n",
    "\n",
    "# Convert to a GeoDataFrame \n",
    "gdf_coords = gpd.GeoDataFrame(\n",
    "    df_coords, \n",
    "    geometry=gpd.points_from_xy(df_coords.lon, df_coords.lat),\n",
    "    crs=\"EPSG:4326\"\n",
    ").to_crs(epsg=3857)      # Web-Mercator\n",
    "\n",
    "# Now extract X,Y in metres\n",
    "aru_coords_mapping = gdf_coords.copy()\n",
    "aru_coords_mapping[\"x\"] = aru_coords_mapping.geometry.x\n",
    "aru_coords_mapping[\"y\"] = aru_coords_mapping.geometry.y\n",
    "aru_coords_mapping = aru_coords_mapping[[\"x\",\"y\"]] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â Wrote file-level recorder coords to /home/bwilliams/ucl_projects/bomb_fishing/code/localisation/aru_coords.csv\n"
     ]
    }
   ],
   "source": [
    "# Load detecttions.csv\n",
    "detections_csv = os.path.join(\n",
    "    BASE_DIR, \"bomb_fishing\", \"code\", \"localisation\", \"detections.csv\"\n",
    ")\n",
    "detections = pd.read_csv(detections_csv, usecols=[\"file\"])\n",
    "\n",
    "# Get each unique file and its recorder prefix (A/B/C)\n",
    "files = detections[\"file\"].unique()\n",
    "aru_coords = pd.DataFrame({\"file\": files})\n",
    "aru_coords[\"site\"] = aru_coords[\"file\"].str[0]\n",
    "\n",
    "# Pull x,y from aru_coords (indexed by \"A\",\"B\",\"C\")\n",
    "aru_coords = aru_coords.set_index(\"file\")\n",
    "aru_coords[[\"x\",\"y\"]] = aru_coords_mapping.loc[aru_coords[\"site\"], [\"x\",\"y\"]].values\n",
    "\n",
    "# Write out CSV mapping each file to its x,y location\n",
    "out_csv = os.path.join(\n",
    "    BASE_DIR, \"bomb_fishing\", \"code\", \"localisation\", \"aru_coords.csv\"\n",
    ")\n",
    "aru_coords[[\"x\",\"y\"]].to_csv(out_csv)\n",
    "print(f\"â Wrote file-level recorder coords to {out_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- I am getting the below error as the detections csv is not actually correct. The example data has window for each file and then 1 or 0 for presence absence. I need to do this, maybe set 5sec windows. Not sure what to do if it cuts a bomb in half though?\n",
    "- Also their recorders are clock synced which mine are not. So make sure I trim audio files down to they all actually start at the right time and rename the files to match.\n",
    "- The fill out the detections csv as above for them.\n",
    "- Then try running the below again OR BETTER STILL just copy the tutorial code directly but make sure I can change the speed of sound. think this is easy to as is already done array.\n",
    "- Then try and get these into coordinates that I can put back onto a map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make aru_coords.csv using the coordinates above and the files in detections csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections_csv = os.path.join(BASE_DIR, \"bomb_fishing\", \"code\", \"localisation\", \"detections.csv\")\n",
    "\n",
    "# Initialize the recorder array with underwater speed of sound\n",
    "array = SynchronizedRecorderArray(\n",
    "    aru_coords, # pass it the df from earlier\n",
    "    speed_of_sound=1541.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: there is no 5sec det window in here\n",
    "# 4) Read 5 s detection windows\n",
    "dets = pd.read_csv(detections_csv)\n",
    "\n",
    "# TODO: this seems over complicated\n",
    "# 5) Parse each WAVâs startâtime from its filename (e.g. \"A_20240702_002800.WAV\")\n",
    "#    then add the offset (start_time seconds) to get an absolute timestamp\n",
    "dets[\"file_timestamp\"] = (\n",
    "    pd.to_datetime(\n",
    "        dets[\"file\"].str.extract(r\"^[ABC]_(\\d{8}_\\d{6})\")[0],\n",
    "        format=\"%Y%m%d_%H%M%S\"\n",
    "    )\n",
    ")\n",
    "dets[\"start_timestamp\"] = dets[\"file_timestamp\"] + \\\n",
    "                          pd.to_timedelta(dets[\"start_time\"], unit=\"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "start_timestamp index must contain timezone-localized datetime.datetime objects, but at least one value in the multi-index 'start_timestamp' column is not a localized datetime.datetime object. See SynchronizedRecorderArray.create_candidate_events() docstring for example.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 12\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 7) Run localization with both algorithms\u001b[39;00m\n\u001b[1;32m      7\u001b[0m loc_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m      8\u001b[0m     min_n_receivers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m      9\u001b[0m     max_receiver_dist\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50_000\u001b[39m,  \u001b[38;5;66;03m# metres\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     max_delay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5.0\u001b[39m              \u001b[38;5;66;03m# seconds â your 5 s window\u001b[39;00m\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m pos_gil \u001b[38;5;241m=\u001b[39m \u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocalize_detections\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocalization_algorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgillette\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mloc_params\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m pos_ls \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mlocalize_detections(\n\u001b[1;32m     18\u001b[0m     dets,\n\u001b[1;32m     19\u001b[0m     localization_algorithm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleast_squares\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloc_params\n\u001b[1;32m     21\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/open_soundscape_env/lib/python3.9/site-packages/opensoundscape/localization/synchronized_recorder_array.py:248\u001b[0m, in \u001b[0;36mSynchronizedRecorderArray.localize_detections\u001b[0;34m(self, detections, max_receiver_dist, localization_algorithm, max_delay, min_n_receivers, cc_threshold, cc_filter, bandpass_ranges, residual_threshold, return_unlocalized, num_workers)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03mAttempt to localize positions of sound sources from clip-level detections across multiple recorders\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;124;03mBioacoustics 23, no. 2 (May 4, 2014): 99â112. https://doi.org/10.1080/09524622.2013.827588.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# create list of SpatialEvents, each SpatialEvent will be used to estimate a location\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m# each SpatialEvent consists of a receiver with a detection, and every other receivers within max_receiver_dist, that also have a detection\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# TDOA estimation and localization will be performed on each SpatialEvent\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;66;03m# multiple SpatialEvents may refer to the same real-world sound event\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m candidate_events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_candidate_events\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdetections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_n_receivers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_receiver_dist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcc_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcc_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbandpass_ranges\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbandpass_ranges\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcc_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcc_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# localize each event with joblib.Parallel for parallelization\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# get back list of PositionEstimate objects\u001b[39;00m\n\u001b[1;32m    260\u001b[0m position_estimates \u001b[38;5;241m=\u001b[39m localize_events_parallel(\n\u001b[1;32m    261\u001b[0m     events\u001b[38;5;241m=\u001b[39mcandidate_events,\n\u001b[1;32m    262\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39mnum_workers,\n\u001b[1;32m    263\u001b[0m     localization_algorithm\u001b[38;5;241m=\u001b[39mlocalization_algorithm,\n\u001b[1;32m    264\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/open_soundscape_env/lib/python3.9/site-packages/opensoundscape/localization/synchronized_recorder_array.py:426\u001b[0m, in \u001b[0;36mSynchronizedRecorderArray.create_candidate_events\u001b[0;34m(self, detections, min_n_receivers, max_receiver_dist, cc_threshold, bandpass_ranges, cc_filter, max_delay)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m([is_localized_dt(dt) \u001b[38;5;28;01mfor\u001b[39;00m dt \u001b[38;5;129;01min\u001b[39;00m dts]):\n\u001b[0;32m--> 426\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    427\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_timestamp index must contain timezone-localized datetime.datetime objects, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    428\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mat least one value in the multi-index \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_timestamp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m column is not a localized datetime.datetime object. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    429\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee SynchronizedRecorderArray.create_candidate_events() docstring for example.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    430\u001b[0m         )\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;66;03m# try to determine start_timestamps from metadata of each audio file\u001b[39;00m\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m         \u001b[38;5;66;03m# initialize instance of helper class used to calculate timestamp from file metadata\u001b[39;00m\n\u001b[1;32m    435\u001b[0m         \u001b[38;5;66;03m# class rather than function to allow caching and re-using timestamp when file remains the same\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: start_timestamp index must contain timezone-localized datetime.datetime objects, but at least one value in the multi-index 'start_timestamp' column is not a localized datetime.datetime object. See SynchronizedRecorderArray.create_candidate_events() docstring for example."
     ]
    }
   ],
   "source": [
    "# 6) Turn into the 4-level multiindex required by OpenSoundscape\n",
    "dets = dets.set_index(\n",
    "    [\"file\", \"start_time\", \"end_time\", \"start_timestamp\"]\n",
    ")[[\"blast\"]]\n",
    "\n",
    "# 7) Run localization with both algorithms\n",
    "loc_params = dict(\n",
    "    min_n_receivers=3,\n",
    "    max_receiver_dist=50_000,  # metres\n",
    "    max_delay=5.0              # seconds â your 5 s window\n",
    ")\n",
    "pos_gil = array.localize_detections(\n",
    "    dets,\n",
    "    localization_algorithm=\"gillette\",\n",
    "    **loc_params\n",
    ")\n",
    "pos_ls = array.localize_detections(\n",
    "    dets,\n",
    "    localization_algorithm=\"least_squares\",\n",
    "    **loc_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7) Run localization with both algorithms\n",
    "loc_params = dict(\n",
    "    min_n_receivers=3,\n",
    "    max_receiver_dist=50_000,  # metres\n",
    "    max_delay=5.0              # seconds â your 5 s window\n",
    ")\n",
    "pos_gil = array.localize_detections(\n",
    "    dets,\n",
    "    localization_algorithm=\"gillette\",\n",
    "    **loc_params\n",
    ")\n",
    "pos_ls = array.localize_detections(\n",
    "    dets,\n",
    "    localization_algorithm=\"least_squares\",\n",
    "    **loc_params\n",
    ")\n",
    "\n",
    "# 8) Convert to DataFrames for inspection\n",
    "df_gil = positions_to_df(pos_gil)\n",
    "df_ls  = positions_to_df(pos_ls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open_soundscape_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
